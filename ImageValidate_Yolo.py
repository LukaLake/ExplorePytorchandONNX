# Ultralytics YOLO ğŸš€, AGPL-3.0 license
""" 
YOLO11 åˆ†å‰²æ¨¡å‹ ONNXRuntime 
    åŠŸèƒ½1: æ”¯æŒä¸ç”¨å°ºå¯¸å›¾åƒçš„è¾“å…¥
    åŠŸèƒ½2: æ”¯æŒå¯è§†åŒ–åˆ†å‰²ç»“æœ
"""

import time
import argparse
import sys
import cv2
import numpy as np
import onnxruntime as ort
from screeninfo import get_monitors

# æ–°è·¯å¾„åˆ—è¡¨
new_paths = [
    r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\bin",
    r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\libnvvp"
]

# æ·»åŠ æ¯ä¸ªæ–°è·¯å¾„åˆ° PATHï¼ˆé¿å…é‡å¤æ·»åŠ ï¼‰
for path in new_paths:
    if path not in sys.path:
        sys.path.insert(0, path)  # æ’å…¥åˆ° sys.path å¼€å¤´ï¼Œä¼˜å…ˆæœç´¢
 
# å®šä¹‰ COCO æ•°æ®é›†çš„ 80 ä¸ªç±»åˆ«åç§°
CLASS_NAMES = [
    'person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus',
    'train', 'truck', 'boat', 'traffic light', 'fire hydrant',
    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',
    'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',
    'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',
    'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',
    'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'potted plant',
    'bed', 'dining table', 'toilet', 'tvmonitor', 'laptop', 'mouse',
    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',
    'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',
    'teddy bear', 'hair drier', 'toothbrush'
]

# å®šä¹‰æ¯ä¸ªç±»åˆ«å¯¹åº”çš„é¢œè‰²ï¼ˆR, G, Bï¼‰
# è¿™é‡Œä½¿ç”¨éšæœºé¢œè‰²ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦è‡ªå®šä¹‰
np.random.seed(42)  # ä¸ºå¯é‡å¤æ€§è®¾ç½®ç§å­
CLASS_COLORS = {i: tuple(np.random.randint(0, 255, 3).tolist()) for i in range(len(CLASS_NAMES))}
 
class YOLO11Seg:
    def __init__(self, onnx_model):
        # åˆ›å»º Ort æ¨ç†ä¼šè¯ï¼Œé€‰æ‹© CPU æˆ– GPU æä¾›è€…
        self.session = ort.InferenceSession(
            onnx_model,
            providers=["CUDAExecutionProvider", "CPUExecutionProvider"]
            if ort.get_device() == "GPU"
            else ["CPUExecutionProvider"],
        )
        print("ä½¿ç”¨æä¾›è€…:", ort.get_device() )
        # æ ¹æ® ONNX æ¨¡å‹ç±»å‹é€‰æ‹© Numpy æ•°æ®ç±»å‹ï¼ˆæ”¯æŒ FP32 å’Œ FP16ï¼‰
        self.ndtype = np.half if self.session.get_inputs()[0].type == "tensor(float16)" else np.single

        # è·å–æ¨¡å‹çš„è¾“å…¥å®½åº¦å’Œé«˜åº¦ï¼ˆYOLO11-seg åªæœ‰ä¸€ä¸ªè¾“å…¥ï¼‰
        self.model_height, self.model_width = [x.shape for x in self.session.get_inputs()][0][-2:]

        # æ‰“å°æ¨¡å‹çš„è¾“å…¥å°ºå¯¸
        print("YOLO11 ğŸš€ å®ä¾‹åˆ†å‰² ONNXRuntime")
        print("æ¨¡å‹åç§°ï¼š", onnx_model)
        print(f"æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼šå®½åº¦ = {self.model_width}, é«˜åº¦ = {self.model_height}")

        # åŠ è½½ç±»åˆ«åç§°
        self.classes = CLASS_NAMES

        # åŠ è½½ç±»åˆ«å¯¹åº”çš„é¢œè‰²
        self.class_colors = CLASS_COLORS
 
    def get_color_for_class(self, class_id):
        return self.class_colors.get(class_id, (255, 255, 255))  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç±»åˆ«é¢œè‰²ï¼Œè¿”å›ç™½è‰²
 
    def __call__(self, im0, conf_threshold=0.4, iou_threshold=0.45, nm=32):
        """
        å®Œæ•´çš„æ¨ç†æµç¨‹ï¼šé¢„å¤„ç† -> æ¨ç† -> åå¤„ç†
        Args:
            im0 (Numpy.ndarray): åŸå§‹è¾“å…¥å›¾åƒ
            conf_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold (float): NMS ä¸­çš„ IoU é˜ˆå€¼
            nm (int): æ©è†œæ•°é‡
        Returns:
            boxes (List): è¾¹ç•Œæ¡†åˆ—è¡¨
            segments (List): åˆ†å‰²åŒºåŸŸåˆ—è¡¨
            masks (np.ndarray): [N, H, W] è¾“å‡ºæ©è†œ
        """
        # å›¾åƒé¢„å¤„ç†
        im, ratio, (pad_w, pad_h) = self.preprocess(im0)
 
        # ONNX æ¨ç†
        preds = self.session.run(None, {self.session.get_inputs()[0].name: im})
 
        # åå¤„ç†
        boxes, segments, masks = self.postprocess(
            preds,
            im0=im0,
            ratio=ratio,
            pad_w=pad_w,
            pad_h=pad_h,
            conf_threshold=conf_threshold,
            iou_threshold=iou_threshold,
            nm=nm,
        )
        return boxes, segments, masks
 
    def preprocess(self, img):
        """
        å›¾åƒé¢„å¤„ç†
        Args:
            img (Numpy.ndarray): è¾“å…¥å›¾åƒ
        Returns:
            img_process (Numpy.ndarray): å¤„ç†åçš„å›¾åƒ
            ratio (tuple): å®½é«˜æ¯”ä¾‹
            pad_w (float): å®½åº¦çš„å¡«å……
            pad_h (float): é«˜åº¦çš„å¡«å……
        """
        # è°ƒæ•´è¾“å…¥å›¾åƒå¤§å°å¹¶ä½¿ç”¨ letterbox å¡«å……
        shape = img.shape[:2]  # åŸå§‹å›¾åƒå¤§å°
        new_shape = (self.model_height, self.model_width)
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
        ratio = r, r
        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
        pad_w, pad_h = (new_shape[1] - new_unpad[0]) / 2, (new_shape[0] - new_unpad[1]) / 2  # å¡«å……å®½é«˜
        if shape[::-1] != new_unpad:  # è°ƒæ•´å›¾åƒå¤§å°
            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
        top, bottom = int(round(pad_h - 0.1)), int(round(pad_h + 0.1))
        left, right = int(round(pad_w - 0.1)), int(round(pad_w + 0.1))
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))
 
        # è½¬æ¢ï¼šHWC -> CHW -> BGR è½¬ RGB -> é™¤ä»¥ 255 -> contiguous -> æ·»åŠ ç»´åº¦
        img = np.ascontiguousarray(np.einsum("HWC->CHW", img)[::-1], dtype=self.ndtype) / 255.0
        img_process = img[None] if len(img.shape) == 3 else img
        return img_process, ratio, (pad_w, pad_h)
 
    def postprocess(self, preds, im0, ratio, pad_w, pad_h, conf_threshold, iou_threshold, nm=32):
        """
        æ¨ç†åçš„ç»“æœåå¤„ç†
        Args:
            preds (Numpy.ndarray): æ¥è‡ª ONNX çš„æ¨ç†ç»“æœ
            im0 (Numpy.ndarray): [h, w, c] åŸå§‹è¾“å…¥å›¾åƒ
            ratio (tuple): å®½é«˜æ¯”ä¾‹
            pad_w (float): å®½åº¦çš„å¡«å……
            pad_h (float): é«˜åº¦çš„å¡«å……
            conf_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold (float): IoU é˜ˆå€¼
            nm (int): æ©è†œæ•°é‡
        Returns:
            boxes (List): è¾¹ç•Œæ¡†åˆ—è¡¨
            segments (List): åˆ†å‰²åŒºåŸŸåˆ—è¡¨
            masks (np.ndarray): æ©è†œæ•°ç»„
        """
        x, protos = preds[0], preds[1]  # è·å–æ¨¡å‹çš„ä¸¤ä¸ªè¾“å‡ºï¼šé¢„æµ‹å’ŒåŸå‹

        # è¾“å‡ºxçš„å‰116ä¸ªæ•°æ®
        print("è¾“å‡ºxçš„å‰15ä¸ªæ•°æ®ï¼š", x[0][0][:15])
        
        # è½¬æ¢ç»´åº¦
        x = np.einsum("bcn->bnc", x)
        print("è¾“å‡ºxçš„å‰15ä¸ªæ•°æ®ï¼š", x[0][0][:15])

        # è¾“å‡ºxå½¢çŠ¶
        print("è¾“å‡ºxå½¢çŠ¶ï¼š", x.shape)
 
        # ç½®ä¿¡åº¦è¿‡æ»¤
        x = x[np.amax(x[..., 4:-nm], axis=-1) > conf_threshold]

        print("ç½®ä¿¡åº¦è¿‡æ»¤åçš„xå½¢çŠ¶ï¼š", x.shape)
        
 
        # åˆå¹¶è¾¹ç•Œæ¡†ã€ç½®ä¿¡åº¦ã€ç±»åˆ«å’Œæ©è†œ
        x = np.c_[x[..., :4], np.amax(x[..., 4:-nm], axis=-1), np.argmax(x[..., 4:-nm], axis=-1), x[..., -nm:]]
 
        # NMS è¿‡æ»¤
        x = x[cv2.dnn.NMSBoxes(x[:, :4], x[:, 4], conf_threshold, iou_threshold)]
 
        # è§£æå¹¶è¿”å›ç»“æœ
        if len(x) > 0:
            # è¾¹ç•Œæ¡†æ ¼å¼è½¬æ¢ï¼šä» cx cy w h -> x y x y
            x[..., [0, 1]] -= x[..., [2, 3]] / 2
            x[..., [2, 3]] += x[..., [0, 1]]
 
            # ç¼©æ”¾è¾¹ç•Œæ¡†ï¼Œä½¿å…¶ä¸åŸå§‹å›¾åƒå°ºå¯¸åŒ¹é…
            x[..., :4] -= [pad_w, pad_h, pad_w, pad_h]
            x[..., :4] /= min(ratio)
 
            # é™åˆ¶è¾¹ç•Œæ¡†åœ¨å›¾åƒè¾¹ç•Œå†…
            x[..., [0, 2]] = x[:, [0, 2]].clip(0, im0.shape[1])
            x[..., [1, 3]] = x[:, [1, 3]].clip(0, im0.shape[0])
 
            # å¤„ç†æ©è†œ
            masks = self.process_mask(protos[0], x[:, 6:], x[:, :4], im0.shape)
 
            # å°†æ©è†œè½¬æ¢ä¸ºåˆ†å‰²åŒºåŸŸ
            segments = self.masks2segments(masks)
            return x[..., :6], segments, masks  # è¿”å›è¾¹ç•Œæ¡†ã€åˆ†å‰²åŒºåŸŸå’Œæ©è†œ
        else:
            return [], [], []
 
    @staticmethod
    def masks2segments(masks):
        """
        å°†æ©è†œè½¬æ¢ä¸ºåˆ†å‰²åŒºåŸŸ
        Args:
            masks (numpy.ndarray): æ¨¡å‹è¾“å‡ºçš„æ©è†œï¼Œå½¢çŠ¶ä¸º (n, h, w)
        Returns:
            segments (List): åˆ†å‰²åŒºåŸŸçš„åˆ—è¡¨
        """
        segments = []
        for x in masks.astype("uint8"):
            c = cv2.findContours(x, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]  # æ‰¾åˆ°è½®å»“
            if c:
                c = np.array(c[np.array([len(x) for x in c]).argmax()]).reshape(-1, 2)
            else:
                c = np.zeros((0, 2))  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†å‰²åŒºåŸŸï¼Œè¿”å›ç©ºæ•°ç»„
            segments.append(c.astype("float32"))
        return segments
 
    @staticmethod
    def crop_mask(masks, boxes):
        """
        è£å‰ªæ©è†œï¼Œä½¿å…¶ä¸è¾¹ç•Œæ¡†å¯¹é½
        Args:
            masks (Numpy.ndarray): [n, h, w] æ©è†œæ•°ç»„
            boxes (Numpy.ndarray): [n, 4] è¾¹ç•Œæ¡†
        Returns:
            (Numpy.ndarray): è£å‰ªåçš„æ©è†œ
        """
        n, h, w = masks.shape
        x1, y1, x2, y2 = np.split(boxes[:, :, None], 4, 1)
        r = np.arange(w, dtype=x1.dtype)[None, None, :]
        c = np.arange(h, dtype=x1.dtype)[None, :, None]
        return masks * ((r >= x1) * (r < x2) * (c >= y1) * (c < y2))
 
    def process_mask(self, protos, masks_in, bboxes, im0_shape):
        """
        å¤„ç†æ¨¡å‹è¾“å‡ºçš„æ©è†œ
        Args:
            protos (numpy.ndarray): [mask_dim, mask_h, mask_w] æ©è†œåŸå‹
            masks_in (numpy.ndarray): [n, mask_dim] æ©è†œæ•°é‡
            bboxes (numpy.ndarray): ç¼©æ”¾åˆ°åŸå§‹å›¾åƒå°ºå¯¸çš„è¾¹ç•Œæ¡†
            im0_shape (tuple): åŸå§‹è¾“å…¥å›¾åƒçš„å°ºå¯¸ (h,w,c)
        Returns:
            (numpy.ndarray): å¤„ç†åçš„æ©è†œ
        """
        c, mh, mw = protos.shape
        masks = np.matmul(masks_in, protos.reshape((c, -1))).reshape((-1, mh, mw)).transpose(1, 2, 0)  # HWN
        masks = np.ascontiguousarray(masks)
        masks = self.scale_mask(masks, im0_shape)  # å°†æ©è†œä» P3 å°ºå¯¸ç¼©æ”¾åˆ°åŸå§‹è¾“å…¥å›¾åƒå¤§å°
        masks = np.einsum("HWN -> NHW", masks)  # HWN -> NHW
        masks = self.crop_mask(masks, bboxes)  # è£å‰ªæ©è†œ
        return np.greater(masks, 0.5)  # è¿”å›äºŒå€¼åŒ–åçš„æ©è†œ
 
    @staticmethod
    def scale_mask(masks, im0_shape, ratio_pad=None):
        """
        å°†æ©è†œç¼©æ”¾è‡³åŸå§‹å›¾åƒå¤§å°
        Args:
            masks (np.ndarray): ç¼©æ”¾å’Œå¡«å……åçš„æ©è†œ
            im0_shape (tuple): åŸå§‹å›¾åƒå¤§å°
            ratio_pad (tuple): å¡«å……ä¸åŸå§‹å›¾åƒçš„æ¯”ä¾‹
        Returns:
            masks (np.ndarray): ç¼©æ”¾åçš„æ©è†œ
        """
        im1_shape = masks.shape[:2]
        if ratio_pad is None:  # è®¡ç®—æ¯”ä¾‹
            gain = min(im1_shape[0] / im0_shape[0], im1_shape[1] / im0_shape[1])  # æ¯”ä¾‹
            pad = (im1_shape[1] - im0_shape[1] * gain) / 2, (im1_shape[0] - im0_shape[0] * gain) / 2  # å¡«å……
        else:
            pad = ratio_pad[1]
 
        # è®¡ç®—æ©è†œçš„è¾¹ç•Œ
        top, left = int(round(pad[1] - 0.1)), int(round(pad[0] - 0.1))  # y, x
        bottom, right = int(round(im1_shape[0] - pad[1] + 0.1)), int(round(im1_shape[1] - pad[0] + 0.1))
        if len(masks.shape) < 2:
            raise ValueError(f'"len of masks shape" åº”è¯¥æ˜¯ 2 æˆ– 3ï¼Œä½†å¾—åˆ° {len(masks.shape)}')
        masks = masks[top:bottom, left:right]
        masks = cv2.resize(
            masks, (im0_shape[1], im0_shape[0]), interpolation=cv2.INTER_LINEAR
        )  # ä½¿ç”¨ INTER_LINEAR æ’å€¼è°ƒæ•´å¤§å°
        if len(masks.shape) == 2:
            masks = masks[:, :, None]
        return masks
 
    def draw_and_visualize(self, im, bboxes, segments, vis=False, save=True):
        """
        ç»˜åˆ¶å’Œå¯è§†åŒ–ç»“æœ
        Args:
            im (np.ndarray): åŸå§‹å›¾åƒï¼Œå½¢çŠ¶ä¸º [h, w, c]
            bboxes (numpy.ndarray): [n, 6]ï¼Œn æ˜¯è¾¹ç•Œæ¡†æ•°é‡
            segments (List): åˆ†å‰²åŒºåŸŸçš„åˆ—è¡¨
            vis (bool): æ˜¯å¦ä½¿ç”¨ OpenCV æ˜¾ç¤ºå›¾åƒ
            save (bool): æ˜¯å¦ä¿å­˜å¸¦æ³¨é‡Šçš„å›¾åƒ
        Returns:
            None
        """
        # åˆ›å»ºå›¾åƒå‰¯æœ¬
        im_canvas = im.copy()

        for (*box, conf, cls_id), segment in zip(bboxes, segments):
            cls_id = int(cls_id)
            if cls_id >= len(self.classes):
                class_name = 'unknown'
                color = (255, 255, 255)  # ç™½è‰²
            else:
                class_name = self.classes[cls_id]
                color = self.class_colors.get(cls_id, (255, 255, 255))  # é»˜è®¤ç™½è‰²

            label = f"{class_name}: {conf:.3f}"

            # ç»˜åˆ¶è½®å»“å’Œå¡«å……æ©è†œ
            if len(segment) > 0:
                cv2.polylines(im, [np.int32(segment)], True, color, 2)  # ç»˜åˆ¶è¾¹æ¡†
                cv2.fillPoly(im_canvas, [np.int32(segment)], color)  # ä½¿ç”¨ç±»åˆ«å¯¹åº”çš„é¢œè‰²å¡«å……å¤šè¾¹å½¢

            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            x1, y1, x2, y2 = map(int, box)
            cv2.rectangle(im, (x1, y1), (x2, y2), color, 2, cv2.LINE_AA)

            # åœ¨å›¾åƒä¸Šç»˜åˆ¶ç±»åˆ«åç§°å’Œç½®ä¿¡åº¦
            cv2.putText(im, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)

        # å°†å›¾åƒå’Œç»˜åˆ¶çš„å¤šè¾¹å½¢æ··åˆ
        im = cv2.addWeighted(im_canvas, 0.3, im, 0.7, 0)

        # è·å–å±å¹•å°ºå¯¸
        monitor = get_monitors()[0]  # è·å–ç¬¬ä¸€ä¸ªç›‘è§†å™¨çš„ä¿¡æ¯
        screen_width, screen_height = monitor.width, monitor.height

        # è®¾ç½®çª—å£å°ºå¯¸ä¸ºå±å¹•å°ºå¯¸çš„90%
        window_width, window_height = int(screen_width * 0.9), int(screen_height * 0.9)

        # è®¡ç®—å›¾åƒç¼©æ”¾æ¯”ä¾‹
        img_height, img_width = im.shape[:2]
        scale = min(window_width / img_width, window_height / img_height, 1.0)  # ä¸æ”¾å¤§å›¾åƒ

        # è°ƒæ•´å›¾åƒå¤§å°ä»¥é€‚åº”çª—å£
        if scale < 1.0:
            new_size = (int(img_width * scale), int(img_height * scale))
            im = cv2.resize(im, new_size, interpolation=cv2.INTER_AREA)

        # åˆ›å»ºå¯è°ƒæ•´å¤§å°çš„çª—å£å¹¶è®¾ç½®å°ºå¯¸
        if vis:
            cv2.namedWindow("Segmentation Result", cv2.WINDOW_NORMAL)
            cv2.resizeWindow("Segmentation Result", im.shape[1], im.shape[0])  # è®¾ç½®çª—å£å¤§å°ä¸ºå›¾åƒå¤§å°
            cv2.imshow("Segmentation Result", im)
            cv2.waitKey(0)
            cv2.destroyAllWindows()

        # ä¿å­˜å›¾åƒ
        if save:
            cv2.imwrite("seg_result_picture.jpg", im)
            print("ç»“æœå·²ä¿å­˜ä¸º 'seg_result_picture.jpg'ã€‚")

 
if __name__ == "__main__":
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, default=r"Models/yolo11n-seg.onnx" , help="ONNX æ¨¡å‹è·¯å¾„")
    parser.add_argument("--source", type=str, default=r"Images/Test11.png", help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--conf", type=float, default=0.7, help="ç½®ä¿¡åº¦é˜ˆå€¼")
    parser.add_argument("--iou", type=float, default=0.45, help="NMS çš„ IoU é˜ˆå€¼")
    args = parser.parse_args()
 
    # åŠ è½½æ¨¡å‹
    model = YOLO11Seg(args.model)
 
    # ä½¿ç”¨ OpenCV è¯»å–å›¾åƒ
    img = cv2.imread(args.source)

    # è®¡ç®—æ¨ç†æ—¶é—´

    start_time = time.time()
    # æ¨¡å‹æ¨ç†
    boxes, segments, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
 
    # å¦‚æœæ£€æµ‹åˆ°ç›®æ ‡ï¼Œç»˜åˆ¶è¾¹ç•Œæ¡†å’Œåˆ†å‰²åŒºåŸŸ
    if len(boxes) > 0:
        model.draw_and_visualize(img, boxes, segments, vis=False, save=True)
    else:
        print("æœªæ£€æµ‹åˆ°ç›®æ ‡ã€‚")

    # è®¡ç®—æ¨ç†æ—¶é—´
    end_time = time.time()
    print("æ¨ç†æ—¶é—´ï¼š", end_time - start_time, "ç§’ã€‚")